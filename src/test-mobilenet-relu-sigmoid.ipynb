{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.compat.v1.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# augmentation\n",
    "train_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Train'\n",
    "test_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Test'\n",
    "val_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Validation'\n",
    "\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(128, 128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    directory=val_dir,\n",
    "    target_size=(128, 128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    directory=val_dir,\n",
    "    target_size=(128, 128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(128, 128, 3)))\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(2, 2))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"sigmoid\")(headModel)\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "plot_model(model, to_file='img/mobile-relu-sigmoid.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "log_dir = \"logs/fit/test-relu-sigmoid\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb = TensorBoard(histogram_freq=1, write_graph=True, write_grads=True, log_dir=log_dir)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    steps_per_epoch=len(train_generator) // 32,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    # validation_steps=len(val_generator) // 32,\n",
    "    # validation_split=0.01\n",
    "    callbacks=[reduce_lr, tb]\n",
    ")\n",
    "\n",
    "# model.evaluate(test_generator)\n",
    "\n",
    "model.save('masknet-relu-sigmoid.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# loading haarcascade_frontalface_default.xml\n",
    "face_model = cv2.CascadeClassifier(\n",
    "    '../input/haar-cascades-for-face-detection/haarcascade_frontalface_default.xml')\n",
    "model = load_model('masknet-relu-sigmoid.h5')\n",
    "mask_label = {0: 'MASK', 1: 'NO MASK'}\n",
    "color_label = {0: (0, 255, 0), 1: (255, 0, 0)}\n",
    "def detect(image_id):\n",
    "    # Read in an image\n",
    "    img = cv2.imread(f'../input/face-mask-detection/images/maksssksksss{image_id}.png')\n",
    "    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n",
    "    # Detect faces\n",
    "    faces = face_model.detectMultiScale(img)\n",
    "    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # colored output image\n",
    "    for i in range(len(faces)):\n",
    "        (x, y, w, h) = faces[i]\n",
    "        crop = new_img[y:y + h, x:x + w]\n",
    "        crop = cv2.resize(crop, (128, 128))\n",
    "        crop = np.reshape(crop, [1, 128, 128, 3]) / 255.0\n",
    "        mask_result = model.predict(crop)\n",
    "        color = color_label[mask_result.argmax()]\n",
    "        cv2.putText(\n",
    "            new_img,\n",
    "            mask_label[mask_result.argmax()],\n",
    "            (x, y - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            color,\n",
    "            2\n",
    "        )\n",
    "        cv2.rectangle(new_img, (x, y), (x+w, y+h), color, 2)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(new_img)\n",
    "\n",
    "detect('331')\n",
    "detect('455')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python38564bite1780c28f4fd4c728966dd797ae24baa"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}